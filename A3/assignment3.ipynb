{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install package"
      ],
      "metadata": {
        "id": "BwPC6oynq7iJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1qhggbBXV0GN",
        "outputId": "01f14518-6df5-49b4-f79b-ebf006b9dabd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting aif360[all]\n",
            "  Downloading aif360-0.5.0-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.1/214.1 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.5.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.2.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.10.1)\n",
            "Collecting BlackBoxAuditing\n",
            "  Downloading BlackBoxAuditing-0.1.54.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: rpy2 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.5.5)\n",
            "Collecting igraph[plotting]\n",
            "  Downloading igraph-0.10.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting adversarial-robustness-toolbox>=1.0.0\n",
            "  Downloading adversarial_robustness_toolbox-1.13.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairlearn~=0.7\n",
            "  Downloading fairlearn-0.8.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.0/235.0 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipympl\n",
            "  Downloading ipympl-0.9.3-py2.py3-none-any.whl (511 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 KB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2<3.1.0\n",
            "  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (4.64.1)\n",
            "Collecting tempeh\n",
            "  Downloading tempeh-0.1.12-py3-none-any.whl (39 kB)\n",
            "Collecting sphinx-rtd-theme\n",
            "  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinx<2\n",
            "  Downloading Sphinx-1.8.6-py2.py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.13.1+cu116)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (2.2.3)\n",
            "Collecting jupyter\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (1.2.3)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (2.11.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (0.11.2)\n",
            "Requirement already satisfied: pytest>=3.5 in /usr/local/lib/python3.8/dist-packages (from aif360[all]) (3.6.4)\n",
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-learn>=1.0\n",
            "  Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360[all]) (1.15.0)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (3.2.2)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (0.6.2.post0)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.8/dist-packages (from cvxpy>=1.0->aif360[all]) (2.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2<3.1.0->aif360[all]) (2.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360[all]) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.0->aif360[all]) (2.8.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (22.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (9.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (1.11.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest>=3.5->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360[all]) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0->aif360[all]) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.25.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (0.7.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (23.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.12.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.18,>=0.11 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (0.16)\n",
            "Collecting sphinxcontrib-websupport\n",
            "  Downloading sphinxcontrib_websupport-1.2.4-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (2.2.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.8/dist-packages (from sphinx<2->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (23.1.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (4.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.31.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.4.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.11.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.51.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (2.11.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (15.0.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (1.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=1.13.1->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from BlackBoxAuditing->aif360[all]) (3.0)\n",
            "Collecting texttable>=1.6.2\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Collecting cairocffi>=1.2.0\n",
            "  Downloading cairocffi-1.4.0.tar.gz (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ipython<9 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (7.9.0)\n",
            "Requirement already satisfied: traitlets<6 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (5.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (8.4.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.8/dist-packages (from ipympl->aif360[all]) (7.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->aif360[all]) (0.11.0)\n",
            "Collecting qtconsole\n",
            "  Downloading qtconsole-5.4.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.8/dist-packages (from jupyter->aif360[all]) (6.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter->aif360[all]) (5.3.4)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.8/dist-packages (from jupyter->aif360[all]) (6.5.4)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.8/dist-packages (from jupyter->aif360[all]) (6.3.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.8/dist-packages (from lime->aif360[all]) (0.19.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from rpy2->aif360[all]) (1.5.1)\n",
            "Requirement already satisfied: cffi>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from rpy2->aif360[all]) (1.15.1)\n",
            "Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0\n",
            "  Downloading sphinxcontrib_jquery-2.0.0-py3-none-any.whl (3.2 kB)\n",
            "Collecting shap\n",
            "  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting memory-profiler\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=1.13.1->aif360[all]) (0.38.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.10.0->rpy2->aif360[all]) (2.21)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython<9->ipympl->aif360[all]) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.6.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from ipywidgets<9,>=7.6.0->ipympl->aif360[all]) (3.0.5)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->aif360[all]) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter->aif360[all]) (6.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.8/dist-packages (from osqp>=0.4.1->cvxpy>=1.0->aif360[all]) (0.1.5.post3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.0.0->sphinx<2->aif360[all]) (1.26.14)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (2023.2.27)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.12->lime->aif360[all]) (1.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (2.2.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (0.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from memory-profiler->tempeh->aif360[all]) (5.4.8)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (0.7.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (4.9.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (6.0.0)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (4.6.3)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (1.2.1)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (5.7.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (1.5.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.8/dist-packages (from nbconvert->jupyter->aif360[all]) (0.7.1)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->aif360[all]) (1.8.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->aif360[all]) (0.16.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->aif360[all]) (23.2.1)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->aif360[all]) (0.13.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.8/dist-packages (from notebook->jupyter->aif360[all]) (21.3.0)\n",
            "Collecting qtpy>=2.0.1\n",
            "  Downloading QtPy-2.3.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.6/83.6 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360[all]) (2.2.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap->tempeh->aif360[all]) (0.56.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.8/dist-packages (from sphinxcontrib-websupport->sphinx<2->aif360[all]) (1.1.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython<9->ipympl->aif360[all]) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter->aif360[all]) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (6.0.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->aif360[all]) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.8/dist-packages (from nbformat>=5.1->nbconvert->jupyter->aif360[all]) (4.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython<9->ipympl->aif360[all]) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.8/dist-packages (from terminado>=0.8.3->notebook->jupyter->aif360[all]) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.8/dist-packages (from argon2-cffi->notebook->jupyter->aif360[all]) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.8/dist-packages (from bleach->nbconvert->jupyter->aif360[all]) (0.5.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap->tempeh->aif360[all]) (0.39.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (3.15.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->aif360[all]) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->aif360[all]) (0.19.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=1.13.1->aif360[all]) (3.2.2)\n",
            "Building wheels for collected packages: BlackBoxAuditing, lime, cairocffi\n",
            "  Building wheel for BlackBoxAuditing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for BlackBoxAuditing: filename=BlackBoxAuditing-0.1.54-py2.py3-none-any.whl size=1394770 sha256=6d26af07e65b496fe14feef5b2a24fbd2bdfe7f6cbb2f91ec540101b66e75eb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/77/36/a32ec1b04c2ebe2c45e88d42f33f22f987e76aad3f297b681e\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283857 sha256=f9e5415710450445b47b8577e940b6aa22332b2a71f49e0ef2adc380986638ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/a6/20/cc1e293fcdb67ede666fed293cb895395e7ecceb4467779546\n",
            "  Building wheel for cairocffi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cairocffi: filename=cairocffi-1.4.0-py3-none-any.whl size=88775 sha256=e0b9f6fb2e4a2cce786e2c77b2bd45b27942d0bc6318d5889e893d2080202594\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a9/c0/5c05f9dd73c21f9a7716690642823cdba55594d17a9bd69daf\n",
            "Successfully built BlackBoxAuditing lime cairocffi\n",
            "Installing collected packages: texttable, sphinxcontrib-websupport, sphinxcontrib-jquery, slicer, qtpy, memory-profiler, jinja2, jedi, igraph, sphinx, scikit-learn, cairocffi, sphinx-rtd-theme, shap, lime, fairlearn, BlackBoxAuditing, aif360, adversarial-robustness-toolbox, tempeh, qtconsole, jupyter, ipympl\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.2\n",
            "    Uninstalling Jinja2-3.1.2:\n",
            "      Successfully uninstalled Jinja2-3.1.2\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 3.5.4\n",
            "    Uninstalling Sphinx-3.5.4:\n",
            "      Successfully uninstalled Sphinx-3.5.4\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.1\n",
            "    Uninstalling scikit-learn-1.2.1:\n",
            "      Successfully uninstalled scikit-learn-1.2.1\n",
            "Successfully installed BlackBoxAuditing-0.1.54 adversarial-robustness-toolbox-1.13.1 aif360-0.5.0 cairocffi-1.4.0 fairlearn-0.8.0 igraph-0.10.4 ipympl-0.9.3 jedi-0.18.2 jinja2-3.0.3 jupyter-1.0.0 lime-0.2.0.1 memory-profiler-0.61.0 qtconsole-5.4.0 qtpy-2.3.0 scikit-learn-1.1.3 shap-0.41.0 slicer-0.0.7 sphinx-1.8.6 sphinx-rtd-theme-1.2.0 sphinxcontrib-jquery-2.0.0 sphinxcontrib-websupport-1.2.4 tempeh-0.1.12 texttable-1.6.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sphinxcontrib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install 'aif360[all]'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "SZXx7nV5q_fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.algorithms.preprocessing.lfr import LFR\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "j0Nd8yMiWN5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define *compute_metric()* function"
      ],
      "metadata": {
        "id": "84b2vOzdrCCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics function\n",
        "from collections import OrderedDict\n",
        "from aif360.metrics import ClassificationMetric\n",
        "\n",
        "def compute_metrics(dataset_true, dataset_pred, \n",
        "                    unprivileged_groups, privileged_groups,\n",
        "                    disp = True):\n",
        "    \"\"\" Compute the key metrics \"\"\"\n",
        "    classified_metric_pred = ClassificationMetric(dataset_true,\n",
        "                                                 dataset_pred, \n",
        "                                                 unprivileged_groups=unprivileged_groups,\n",
        "                                                 privileged_groups=privileged_groups)\n",
        "    metrics = OrderedDict()\n",
        "    metrics[\"Balanced accuracy\"] = 0.5*(classified_metric_pred.true_positive_rate()+\n",
        "                                             classified_metric_pred.true_negative_rate())\n",
        "    metrics[\"Statistical parity difference\"] = classified_metric_pred.statistical_parity_difference()\n",
        "    metrics[\"Disparate impact\"] = classified_metric_pred.disparate_impact()\n",
        "    metrics[\"Average odds difference\"] = classified_metric_pred.average_odds_difference()\n",
        "    metrics[\"Equal opportunity difference\"] = classified_metric_pred.equal_opportunity_difference()\n",
        "    metrics[\"Theil index\"] = classified_metric_pred.theil_index()\n",
        "    \n",
        "    if disp:\n",
        "        for k in metrics:\n",
        "            print(\"%s = %.4f\" % (k, metrics[k]))\n",
        "    \n",
        "    return metrics"
      ],
      "metadata": {
        "id": "QXzGkJdbWXfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get dataset, encode string variables, and split into training and testing sets"
      ],
      "metadata": {
        "id": "0gXcEyHHrIY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the dataset and split into train and test\n",
        "df_unprocessed = pd.read_csv(\"https://raw.githubusercontent.com/oliver-miller/ECSE557/master/A3/heart_assignment3.csv\")\n",
        "\n",
        "df = df_unprocessed.copy()\n",
        "\n",
        "# Define the headers of the data to facilitate code at the end of the cell (when splitting into X and y data)\n",
        "headers = df.columns.to_list()\n",
        "\n",
        "# Encode string parameters as integers\n",
        "# Will facilitate the data analysis and binary classifier\n",
        "# Male = 1, female = 0 (for privileged and unprivileged groups)\n",
        "df['Sex'] = df['Sex'].replace(\"M\", 1)\n",
        "df['Sex'] = df['Sex'].replace(\"F\", 0)\n",
        "df['ExerciseAngina'] = df['ExerciseAngina'].replace(\"N\", 0)\n",
        "df['ExerciseAngina'] = df['ExerciseAngina'].replace(\"Y\", 1)\n",
        "df['ChestPainType'] = df['ChestPainType'].replace(\"ASY\", 0)\n",
        "df['ChestPainType'] = df['ChestPainType'].replace(\"NAP\", 1)\n",
        "df['ChestPainType'] = df['ChestPainType'].replace(\"TA\", 2)\n",
        "df['ChestPainType'] = df['ChestPainType'].replace(\"ATA\", 3)\n",
        "df['RestingECG'] = df['RestingECG'].replace(\"Normal\", 0)\n",
        "df['RestingECG'] = df['RestingECG'].replace(\"LVH\", 1)\n",
        "df['RestingECG'] = df['RestingECG'].replace(\"ST\", 2)\n",
        "df['ST_Slope'] = df['ST_Slope'].replace(\"Flat\", 0)\n",
        "df['ST_Slope'] = df['ST_Slope'].replace(\"Down\", 1)\n",
        "df['ST_Slope'] = df['ST_Slope'].replace(\"Up\", 2)\n",
        "# White = 1, everyone else = 0 (for privileged and unprivileged groups)\n",
        "df['Race'] = df['Race'].replace(\"White\", 1)\n",
        "df['Race'] = df['Race'].replace(\"Black\", 0)\n",
        "df['Race'] = df['Race'].replace(\"Asian\", 0)\n",
        "df['Race'] = df['Race'].replace(\"Hispanic \", 0)\n",
        "df['Race'] = df['Race'].replace(\"Other\", 0)\n",
        "\n",
        "X = df.drop(columns=['HeartDisease'], inplace=False)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# Split into training and testing data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=True)"
      ],
      "metadata": {
        "id": "xSHfopKmWf74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit and predict for standard LogisticRegression classifier"
      ],
      "metadata": {
        "id": "6X-KWFbWrPKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit and predict with logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = np.sum(y_test == y_pred) / len(y_pred)\n",
        "print(\"ACCURACY: \" + str(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cY3olrEp8gz",
        "outputId": "6b9a6bb8-0712-4654-b677-0b6ed878f881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACCURACY: 0.8745874587458746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. [PA] For the classifier that you created in last assignment (the non-private classifier), use AIF 360 to set-up and calculate three different fairness metrics. Calculate these metrics for different groups based on the groups you identified as privileged and unprivileged in step 2."
      ],
      "metadata": {
        "id": "5FKOb6B3pmNR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define privileged and unprivileged groups"
      ],
      "metadata": {
        "id": "sA4xMDctqDN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "privileged_groups_sex = [{'Sex': 1}]\n",
        "unprivileged_groups_sex = [{'Sex': 0}]\n",
        "\n",
        "privileged_groups_race = [{'Race': 1}]\n",
        "unprivileged_groups_race = [{'Race': 0}]"
      ],
      "metadata": {
        "id": "G1nHbuRDqB2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fairess metrics on training data"
      ],
      "metadata": {
        "id": "8XfoLfkapxYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format training dataset to use package functions\n",
        "X_train_fair = X_train.copy(deep=True)\n",
        "y_train_fair = y_train.copy(deep=True)\n",
        "df_train_fair = pd.concat([X_train_fair, y_train_fair], axis=1)\n",
        "\n",
        "# Create binary label datasets for sex and race groups\n",
        "df_train_fair_BLD_sex = BinaryLabelDataset(\n",
        "    df=df_train_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Sex\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "df_train_fair_BLD_race = BinaryLabelDataset(\n",
        "    df=df_train_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Race\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "\n",
        "# Create binary label dataset metrics for sex and race groups\n",
        "metric_train_sex = BinaryLabelDatasetMetric(df_train_fair_BLD_sex, \n",
        "                                                 unprivileged_groups=unprivileged_groups_sex,\n",
        "                                                 privileged_groups=privileged_groups_sex)\n",
        "metric_train_race = BinaryLabelDatasetMetric(df_train_fair_BLD_race, \n",
        "                                                  unprivileged_groups=unprivileged_groups_race,\n",
        "                                                  privileged_groups=privileged_groups_race)\n",
        "\n",
        "# Print results\n",
        "print(\"SEX\")\n",
        "print(\"Privileged group: Male, unprivileged group: female\")\n",
        "print(\"Statistical Parity Difference: {}\".format(metric_train_sex.statistical_parity_difference()))\n",
        "print(\"Disparate Impact: {}\".format(metric_train_sex.disparate_impact()))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"RACE\")\n",
        "print(\"Privileged group: White, unprivileged group: black, asian, hispanic, other\")\n",
        "print(\"Statistical Parity Difference: {}\".format(metric_train_race.statistical_parity_difference()))\n",
        "print(\"Disparate Impact: {}\".format(metric_train_race.disparate_impact()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzbCaqLiiM-m",
        "outputId": "969fdd9a-b147-43de-a5bd-132b2b7f3ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEX\n",
            "Privileged group: Male, unprivileged group: female\n",
            "Statistical Parity Difference: -0.3594907407407408\n",
            "Disparate Impact: 0.4190048634493079\n",
            "\n",
            "\n",
            "RACE\n",
            "Privileged group: White, unprivileged group: black, asian, hispanic, other\n",
            "Statistical Parity Difference: -0.05821676078028748\n",
            "Disparate Impact: 0.900643394934976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fairness metrics on testing data"
      ],
      "metadata": {
        "id": "-5BzLOg8p376"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format testing dataset to use package functions\n",
        "y_pred_Series = pd.Series(y_pred, name=\"HeartDisease\", index=y_test.index)\n",
        "df_test_fair = pd.concat([X_test, y_test], axis=1)\n",
        "df_pred_fair = pd.concat([X_test, y_pred_Series], axis=1)\n",
        "\n",
        "# Create binary label datasets for sex and race groups\n",
        "# Test data\n",
        "df_test_fair_BLD_sex = BinaryLabelDataset(\n",
        "    df=df_test_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Sex\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "df_test_fair_BLD_race = BinaryLabelDataset(\n",
        "    df=df_test_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Race\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "# Predicted data\n",
        "df_pred_fair_BLD_sex = BinaryLabelDataset(\n",
        "    df=df_pred_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Sex\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "df_pred_fair_BLD_race = BinaryLabelDataset(\n",
        "    df=df_pred_fair, \n",
        "    label_names=[\"HeartDisease\"], \n",
        "    protected_attribute_names=[\"Race\"],\n",
        "    favorable_label=1.0,\n",
        "    unfavorable_label=0.0\n",
        "    )\n",
        "\n",
        "# Create binary label dataset metrics for sex and race groups\n",
        "# Sex\n",
        "print(\"SEX\")\n",
        "sex_fairness_metrics = compute_metrics(df_test_fair_BLD_sex, \n",
        "                                       df_pred_fair_BLD_sex, \n",
        "                                       unprivileged_groups_sex, \n",
        "                                       privileged_groups_sex,\n",
        "                                       disp=False)\n",
        "print(\"\\n\")\n",
        "# Race\n",
        "print(\"RACE\")\n",
        "race_fairness_metrics = compute_metrics(df_test_fair_BLD_race, \n",
        "                                        df_pred_fair_BLD_race, \n",
        "                                        unprivileged_groups_race, \n",
        "                                        privileged_groups_race,\n",
        "                                        disp=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R9DU6cTnieY",
        "outputId": "9425d8d1-37e0-4f75-f861-78f1d45d004e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEX\n",
            "OrderedDict([('Balanced accuracy', 0.8734117752326414),\n",
            "             ('Statistical parity difference', -0.5101337086558762),\n",
            "             ('Disparate impact', 0.23323460968902054),\n",
            "             ('Average odds difference', -0.3111825316577591),\n",
            "             ('Equal opportunity difference', -0.5254658385093167),\n",
            "             ('Theil index', 0.09210864395493067)])\n",
            "\n",
            "\n",
            "RACE\n",
            "OrderedDict([('Balanced accuracy', 0.8734117752326414),\n",
            "             ('Statistical parity difference', -0.125),\n",
            "             ('Disparate impact', 0.8125),\n",
            "             ('Average odds difference', -0.047495277983082826),\n",
            "             ('Equal opportunity difference', -0.09196025293586263),\n",
            "             ('Theil index', 0.09210864395493067)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. [PA][DA] Prioritize has now asked you to do some pre-processing to minimize unfairness for TriageAssist. Using AIF 360, implement one pre-processing mitigation technique covered in class."
      ],
      "metadata": {
        "id": "UN0iAuAPuiCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for consistency between runs (facilitates debugging)\n",
        "seed = 0\n",
        "\n",
        "# Learning fair representations dataset for sex and race groups   \n",
        "TR_sex = LFR(unprivileged_groups=unprivileged_groups_sex,\n",
        "             privileged_groups=privileged_groups_sex,\n",
        "             k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
        "             verbose=0,\n",
        "             seed=seed\n",
        "        )\n",
        "\n",
        " \n",
        "TR_race = LFR(unprivileged_groups=unprivileged_groups_race,\n",
        "              privileged_groups=privileged_groups_race,\n",
        "              k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
        "              verbose=0,\n",
        "              seed=seed\n",
        "        )\n",
        "\n",
        "# Fit and transform sex and race groups\n",
        "TR_sex = TR_sex.fit(df_train_fair_BLD_sex, maxiter=5000, maxfun=5000)\n",
        "df_train_fair_BLD_sex_TR = TR_sex.transform(df_train_fair_BLD_sex)\n",
        "\n",
        "TR_race = TR_race.fit(df_train_fair_BLD_race, maxiter=5000, maxfun=5000)\n",
        "df_train_fair_BLD_race_TR = TR_race.transform(df_train_fair_BLD_race)\n",
        "\n",
        "# Create binary label dataset metrics for sex and race groups (tranformed)\n",
        "metric_train_sex_TR = BinaryLabelDatasetMetric(df_train_fair_BLD_sex_TR, \n",
        "                                                 unprivileged_groups=unprivileged_groups_sex,\n",
        "                                                 privileged_groups=privileged_groups_sex)\n",
        "metric_train_race_TR = BinaryLabelDatasetMetric(df_train_fair_BLD_race_TR, \n",
        "                                                  unprivileged_groups=unprivileged_groups_race,\n",
        "                                                  privileged_groups=privileged_groups_race)\n",
        "\n",
        "# Print results\n",
        "print(\"SEX\")\n",
        "print(\"Privileged group: Male, unprivileged group: female\")\n",
        "print(\"Statistical Parity Difference: {}\".format(metric_train_sex_TR.statistical_parity_difference()))\n",
        "print(\"Disparate Impact: {}\".format(metric_train_sex_TR.disparate_impact()))\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"RACE\")\n",
        "print(\"Privileged group: White, unprivileged group: black, asian, hispanic, other\")\n",
        "print(\"Statistical Parity Difference: {}\".format(metric_train_race_TR.statistical_parity_difference()))\n",
        "print(\"Disparate Impact: {}\".format(metric_train_race_TR.disparate_impact()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vini6S4iugLW",
        "outputId": "19a10fdb-a303-4c54-ec9b-ebb0eb9c144f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SEX\n",
            "Privileged group: Male, unprivileged group: female\n",
            "Statistical Parity Difference: 0.0\n",
            "Disparate Impact: 1.0\n",
            "\n",
            "\n",
            "RACE\n",
            "Privileged group: White, unprivileged group: black, asian, hispanic, other\n",
            "Statistical Parity Difference: -0.0771143480492813\n",
            "Disparate Impact: 0.700889801505818\n"
          ]
        }
      ]
    }
  ]
}